{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5db51f",
   "metadata": {},
   "source": [
    "## Assignment Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073304e5",
   "metadata": {},
   "source": [
    "__Q1. What is the KNN algorithm?__\n",
    "\n",
    "A1. The K-nearest neighbors (KNN) algorithm is a machine learning algorithm used for both classification and regression tasks. It operates on the principle of proximity, where the class or value of an unknown sample is predicted based on the classes or values of its K nearest neighbors in the feature space.\n",
    "\n",
    "__Q2. How do you choose the value of K in KNN?__\n",
    "\n",
    "A2. The choice of the value K in KNN is crucial and depends on the dataset and problem at hand. A smaller value of K makes the algorithm more sensitive to noise and can lead to overfitting, while a larger value of K can result in oversmoothing and loss of local patterns. The value of K is typically chosen using techniques like cross-validation, grid search, or domain knowledge to strike a balance between bias and variance.\n",
    "\n",
    "__Q3. What is the difference between KNN classifier and KNN regressor?__\n",
    "\n",
    "A3. The difference lies in the nature of the prediction task. KNN classifier is used for classification problems, where the goal is to assign a class label to a given input. KNN regressor, on the other hand, is used for regression problems, where the goal is to predict a continuous value or quantity.\n",
    "\n",
    "__Q4. How do you measure the performance of KNN?__\n",
    "\n",
    "A4. The performance of KNN can be measured using various evaluation metrics depending on the task at hand. For classification, common metrics include accuracy, precision, recall, F1 score, and area under the ROC curve. For regression, metrics like mean squared error (MSE), mean absolute error (MAE), or R-squared can be used.\n",
    "\n",
    "__Q5. What is the curse of dimensionality in KNN?__\n",
    "\n",
    "A5. The curse of dimensionality refers to the phenomenon where the performance of KNN deteriorates as the number of dimensions (features) in the dataset increases. In high-dimensional spaces, the density of training data becomes sparse, and the notion of proximity becomes less meaningful. This can lead to increased computational complexity and poor generalization of the KNN algorithm.\n",
    "\n",
    "__Q6. How do you handle missing values in KNN?__\n",
    "\n",
    "A6. In KNN, missing values can be handled by imputing them with appropriate values. One common approach is to replace missing values with the mean or median of the feature column. Another approach is to assign the missing value as a separate category or to impute it based on the values of its K nearest neighbors.\n",
    "\n",
    "__Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?__\n",
    "\n",
    "A7. The performance of KNN classifier and regressor depends on the specific problem and the underlying data. KNN classifier is suitable for categorical or discrete class prediction problems, while KNN regressor is appropriate for continuous value prediction problems. The choice between them should align with the nature of the target variable and the problem requirements.\n",
    "\n",
    "__Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?__\n",
    "\n",
    "A8. The strengths of KNN include its simplicity, non-parametric nature, and ability to handle multi-class problems. However, its weaknesses include sensitivity to the choice of K, computational inefficiency with large datasets, and vulnerability to noisy or irrelevant features. These limitations can be addressed through careful selection of K, feature selection or dimensionality reduction techniques, and optimization strategies like KD-trees for efficient nearest neighbor search.\n",
    "\n",
    "__Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?__\n",
    "\n",
    "A9. Euclidean distance is a measure of straight-line or \"as-the-crow-flies\" distance between two points in Euclidean space. It calculates the square root of the sum of squared differences between corresponding coordinates. Manhattan distance, also known as city block distance or L1 norm, calculates the sum of absolute differences between corresponding coordinates. The main difference is the way distance is measured, with Euclidean distance being influenced by diagonal distances and Manhattan distance restricted to vertical and horizontal distances.\n",
    "\n",
    "__Q10. What is the role of feature scaling in KNN?__\n",
    "\n",
    "A10. Feature scaling is important in KNN because the algorithm calculates distances between samples based on the feature values. If the features have different scales or units, those with larger values may dominate the distance calculation, leading to biased results. Therefore, it is advisable to perform feature scaling to bring all features to a similar scale, often using techniques like normalization (min-max scaling) or standardization (z-score scaling), before applying KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08530a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
